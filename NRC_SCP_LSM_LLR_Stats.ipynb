{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRC Hashtag Emotion Corpus\n",
    "## Tests for SCP (Cohestion & Accommodation), LSM, LLR, and Stats tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate emotion tags for Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict,Counter\n",
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import seaborn as sns \n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "\n",
    "import SCP_Code as scp\n",
    "\n",
    "import NRCHash as nrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetData = pd.read_csv('pairs_edit_utf_noSquig.csv', sep='~',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdataA = pd.read_csv('A_Tweets_Tagged.txt', sep='\\t', header=None)\n",
    "tagdataA.columns = ['Tokens', 'Tags', 'Conf','Raw Tweet']\n",
    "tagdataB = pd.read_csv('B_Tweets_Tagged.txt', sep='\\t', header=None)\n",
    "tagdataB.columns = ['Tokens', 'Tags', 'Conf','Raw Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NRC Hashtag Emotion Lexicon into lists:\n",
    "wordList = defaultdict(list)\n",
    "emotionList = defaultdict(list)\n",
    "#with open ('C:/Users/Harper/Documents/Practice for Dissertation/NRC-Sentiment-Emotion-Lexicons/AutomaticallyGeneratedLexicons/NRC-Hashtag-Emotion-Lexicon-v0.2/NRC-Hashtag-Emotion-Lexicon-v0.2.txt','r') as f:\n",
    "with open ('/its/home/kh414/Documents/Dissertation/Code_To_Parse/NRC-Sentiment-Emotion-Lexicons/NRC-Sentiment-Emotion-Lexicons/AutomaticallyGeneratedLexicons/NRC-Hashtag-Emotion-Lexicon-v0.2/NRC-Hashtag-Emotion-Lexicon-v0.2.txt','r') as f:\n",
    "    reader = csv.reader(f, delimiter = '\\t')\n",
    "    headerRows = [i for i in range (0,46)] # why 46?\n",
    "    for row in headerRows:\n",
    "        next(reader)\n",
    "    for Affect, word, score in reader: # <AffectCategory><tab><term><tab><score>\n",
    "        # The higher the value, the stronger is the association. \n",
    "        if float(score) > 0.1: # Automatically filter out values less than 0.1. \n",
    "            wordList[word].append(Affect)\n",
    "            emotionList[Affect].append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate emotion count using the word list generated by the above lexicon. \n",
    "def generateEmotionCount(string):\n",
    "    emoCount = Counter()\n",
    "    for token in string.split():\n",
    "        token = token.lower()\n",
    "        emoCount += Counter(wordList[token])\n",
    "    return emoCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty tokens with null word without emotion\n",
    "tagdataA.fillna({'Tokens':'null'}, inplace=True)\n",
    "tagdataB.fillna({'Tokens':'null'}, inplace=True)\n",
    "\n",
    "emotionCountsA = [generateEmotionCount(tweet) for tweet in tagdataA.Tokens]\n",
    "emotionCountsB = [generateEmotionCount(tweet) for tweet in tagdataB.Tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanTestA = pd.DataFrame(emotionCountsA)\n",
    "nanTestB = pd.DataFrame(emotionCountsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate null values in this lexicon\n",
    "asum = nanTestA.isnull().sum()\n",
    "bsum = nanTestB.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  sadness  surprise  trust\n",
       "0    5.0           5.0      NaN   5.0  4.0      1.0       7.0    1.0\n",
       "1    5.0           5.0      NaN   5.0  4.0      1.0       7.0    1.0\n",
       "2    6.0           1.0      2.0   1.0  NaN      1.0       NaN    2.0\n",
       "3    NaN           1.0      2.0   1.0  NaN      1.0       NaN    3.0\n",
       "4    3.0           5.0      2.0   4.0  1.0      2.0       4.0    2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionCountsADF = pd.DataFrame(emotionCountsA, index = tagdataA.index)\n",
    "emotionCountsBDF = pd.DataFrame(emotionCountsB, index = tagdataB.index)\n",
    "emotionCountsADF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop last in emotioncountsA and tagdataA\n",
    "tagdataA= tagdataA.drop(tagdataA.index[len(tagdataA)-1])\n",
    "emotionCountsADF = emotionCountsADF.drop(emotionCountsADF.index[len(emotionCountsADF)-1])\n",
    "len(emotionCountsADF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  sadness  surprise  trust\n",
       "0    3.0           5.0      4.0   4.0  2.0      NaN       1.0    2.0\n",
       "1    2.0           1.0      3.0   1.0  NaN      NaN       3.0    1.0\n",
       "2    1.0           1.0      NaN   2.0  1.0      3.0       NaN    1.0\n",
       "3    3.0           3.0      3.0   1.0  1.0      2.0       3.0    3.0\n",
       "4    1.0           NaN      1.0   NaN  3.0      1.0       5.0    NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "shufBDF = shuffle(emotionCountsBDF).reset_index(drop=True)\n",
    "shufBDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['anger','anticipation','disgust','fear','joy','sadness','surprise','trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the shared markers between tweet-reply messages. \n",
    "def getsharedNRCSentiment(markers,emotionA,emotionB):\n",
    "    score = []\n",
    "    count = Counter()\n",
    "    for item in range(len(emotionA)):\n",
    "        temp = []\n",
    "        for mark in markers:\n",
    "            if(emotionA[mark][item] > 1 and emotionB[mark][item] > 1):  # Filter noisy sentiment (low value)\n",
    "                temp.append(mark)\n",
    "        score.append(temp)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['anger', 'anticipation', 'fear', 'joy'], ['anger'], [], [], ['fear', 'surprise']]\n"
     ]
    }
   ],
   "source": [
    "sharedHash = getsharedNRCSentiment(markers,emotionCountsADF,emotionCountsBDF)\n",
    "print(sharedHash[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['anger', 'anticipation', 'fear', 'joy'], ['anger', 'surprise'], [], ['disgust', 'trust'], ['surprise']]\n"
     ]
    }
   ],
   "source": [
    "sharedHashRand = getsharedNRCSentiment(markers,emotionCountsADF,shufBDF)\n",
    "print(sharedHashRand[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get natural and random shared counts for LLR analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flatten shared lists:\n",
    "flat_share = [item for sublist in sharedHash for item in sublist]\n",
    "flat_shuff = [item for sublist in sharedHashRand for item in sublist]\n",
    "print(len(flat_share),len(flat_shuff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterShared = Counter(flat_share)\n",
    "counterRandShuf = Counter(flat_shuff)\n",
    "\n",
    "print(counterShared)\n",
    "print('\\n',counterRandShuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate frequency list for LLR analysis\n",
    "\n",
    "countershareddf = pd.DataFrame.from_dict(counterShared,orient='index')\n",
    "dtemp = pd.DataFrame.from_dict(counterRandShuf,orient='index')\n",
    "dtemp.columns = ['Shared Rand']\n",
    "countershareddf.columns = ['Shared']\n",
    "countershareddf['Rand Shared'] = dtemp['Shared Rand']\n",
    "\n",
    "countershareddf['Difference'] = countershareddf['Shared'] - countershareddf['Rand Shared']\n",
    "countershareddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countershareddf.sum())\n",
    "\n",
    "with open ('SharedFreq.tex','w') as tf:\n",
    "    tf.write(countershareddf.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': [0.2270217403967906, 0.19553480272375806, 0.03148693767303254],\n",
       " 'anticipation': [0.18988125714741222,\n",
       "  0.16013269276168343,\n",
       "  0.029748564385728787],\n",
       " 'disgust': [0.18535903386915292, 0.1513611125589039, 0.033997921310249035],\n",
       " 'fear': [0.12885423724656386, 0.10179447951509503, 0.027059757731468834],\n",
       " 'joy': [0.1376411470197782, 0.10891966385317951, 0.028721483166598685],\n",
       " 'sadness': [0.055302958300502504, 0.04272964462989818, 0.012573313670604325],\n",
       " 'surprise': [0.2760518384753822, 0.2485168640604353, 0.027534974414946928],\n",
       " 'trust': [0.0998414922417044, 0.08033001499231988, 0.019511477249384512]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCP_ScoresNRC = scp.CalculateAllCohesion(markers,sharedHash,sharedHashRand)\n",
    "SCP_ScoresNRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CohesionDF = pd.DataFrame.from_dict(SCP_ScoresNRC,orient = 'index')\n",
    "CohesionDF.columns = ['TweetReply Cohesion', 'RandomReply Cohesion','Subtractive Cohesion Score']\n",
    "CohesionDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to latex\n",
    "with open ('CohesionTable_NRCHashSent_SCP.tex','w') as tf:\n",
    "    tf.write(CohesionDF.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = CohesionDF['Subtractive Cohesion Score'].sort_values().plot(kind = 'barh',legend = False, color = 'steelblue')#,figsize = (20,10))\n",
    "                    \n",
    "#plot1.tick_params(labelbottom=False, bottom=False,which='both')\n",
    "plt.xlabel('SCP Score')\n",
    "plt.ylabel('Sentiment Marker')\n",
    "plt.title('Subtractive Global Alignment NRC Emotion')\n",
    "plt.savefig('SubtractiveGlobalAlignment_SentimentNRC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateLSM(markers,TweetTagsA,TweetTagsB):\n",
    "    allLSM = {}\n",
    "    allTweets = len(TweetTagsA) # total number of tweets\n",
    "    for mark in markers: \n",
    "        pA = (countMarkers2(mark,TweetTagsA)/allTweets)\n",
    "        pB = (countMarkers2(mark,TweetTagsB)/allTweets)\n",
    "        numerator = abs(pA-pB)\n",
    "        denominator = pA + pB\n",
    "        LSMScore = (1 - (numerator/denominator))\n",
    "        allLSM[mark] = [pA,pB,LSMScore]\n",
    "    return allLSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSM_Sentiment = CalculateLSM(markers, emotionCountsADF,emotionCountsBDF)\n",
    "LSM_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to iterate through a NRC dataframe of emotion counts per message and return a tally if the value \n",
    "# is greater than 0.\n",
    "def countMarkers2(marker, message_set):\n",
    "    tally = 0\n",
    "    for countItem in message_set[marker]:\n",
    "        if countItem > 1:\n",
    "            tally+=1\n",
    "    return tally\n",
    "countMarkers2('anger',emotionCountsADF[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSMdf = pd.DataFrame.from_dict(LSM_Sentiment,orient = 'index')\n",
    "LSMdf.columns = ['pA', 'pB','LSM Score']\n",
    "LSMdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to latex\n",
    "with open ('LSMTable_SentimentNRCHash.tex','w') as tf:\n",
    "    tf.write(LSMdf.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataframe to horizontal bar chart\n",
    "plot1 = LSMdf['LSM Score'].sort_values().plot(kind = 'barh',legend = False, color = 'steelblue')#,figsize = (20,10))\n",
    "                    \n",
    "#plot1.tick_params(labelbottom=False, bottom=False,which='both')\n",
    "plt.xlabel('LSM Score')\n",
    "plt.xlim(0.95,1.005)\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Linguistic Style Matching Sentiment - NRC Hashtag')\n",
    "plt.savefig('LSM_Sentiment_NRCHash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FunctionsForLLR as llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random: sharedRandSentAnB\n",
    "LLR_Sent = llr.getLLR(emotionCountsA,emotionCountsB,sharedHash,markers)\n",
    "LLR_Sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLRSentDF = pd.DataFrame.from_dict(LLR_Sent, orient='index')\n",
    "LLRSentDF.columns = ['LLR Scores Sentiment']\n",
    "LLRSentDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataframe to horizontal bar chart\n",
    "plot1 = LLRSentDF['LLR Scores Sentiment'].sort_values().plot(kind = 'barh', color = 'SteelBlue')#,figsize = (20,10))\n",
    "                    \n",
    "#plot1.tick_params(labelbottom=False, bottom=False,which='both')\n",
    "plt.xlabel('LLR Score')\n",
    "plt.ylabel('Sentiment Marker')\n",
    "plt.title('LLR Score for Sentiment Markers')\n",
    "plt.savefig('LLRScores_Sentiment_NRCHash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scramble replies in countdictB for random \n",
    "\n",
    "shuffledCountDictB = random.sample(emotionCountsB,len(emotionCountsB))\n",
    "print(shuffledCountDictB[0:5],'\\n',emotionCountsB[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedNew = scp.getSharedMarkers(shuffledCountDictB,emotionCountsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random: sharedRandSentAnB\n",
    "LLR_Sent_Rand = llr.getLLR(emotionCountsA,emotionCountsB,sharedNew,markers)\n",
    "LLR_Sent_Rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLRSentDFR = pd.DataFrame.from_dict(LLR_Sent_Rand, orient='index')\n",
    "LLRSentDFR.columns = ['LLR Scores Sentiment Random']\n",
    "LLRSentDFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataframe to horizontal bar chart\n",
    "plot1 = LLRSentDFR['LLR Scores Sentiment Random'].sort_values().plot(kind = 'barh', color = 'SteelBlue')#,figsize = (20,10))\n",
    "                    \n",
    "#plot1.tick_params(labelbottom=False, bottom=False,which='both')\n",
    "plt.xlabel('LLR Score')\n",
    "plt.ylabel('Sentiment Marker')\n",
    "plt.title('LLR Score for Baseline Sentiment Markers')\n",
    "plt.savefig('LLRScores_Sentiment_NRCHash_Baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to latex\n",
    "with open ('LLR_Sentiment_NRC_Hash_Rand.tex','w') as tf:\n",
    "    tf.write(LLRSentDFR.to_latex())\n",
    "with open ('LLR_Sentiment_NRC_Hash.tex','w') as tf2:\n",
    "    tf2.write(LLRSentDF.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PScore for NRC Emotion Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(emotionCountsA[-1])\n",
    "print(len(emotionCountsA),len(emotionCountsB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fishers to find statistical significance of pos tag results:\n",
    "\n",
    "fishScore = scp.getFishersPVal(emotionCountsA,emotionCountsB,sharedNew,markers)\n",
    "fishScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframes\n",
    "fishScoreDF = pd.DataFrame.from_dict(fishScore, orient='index')\n",
    "fishScoreDF.columns = ['P-Score Sent Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('P_Score_NRCHash.tex','w') as tf:\n",
    "    tf.write(fishScoreDF.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishScoreDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accommodation for Sentiment Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single dictionary for A-tweet emotions and b-tweet emotions\n",
    "EmotDict = {}\n",
    "listEmotA = []\n",
    "for item in emotionCountsA:\n",
    "    tempA = []\n",
    "    for value in item:\n",
    "        tempA.append(value)\n",
    "    listEmotA.append(tempA)\n",
    "EmotDict['ASent'] = listEmotA\n",
    "\n",
    "listEmotB = []\n",
    "for item in emotionCountsB:\n",
    "    tempA = []\n",
    "    for value in item:\n",
    "        tempA.append(value)\n",
    "    listEmotB.append(tempA)\n",
    "EmotDict['BSent'] = listEmotB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmotDF = pd.DataFrame.from_dict(EmotDict)\n",
    "EmotDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate Dataframe with Username Pairs, and append that to the sentiment dataframe\n",
    "pairs = []\n",
    "for i in range(len(tweetData)):\n",
    "    pairs.append(tuple([tweetData.a_username[i],tweetData.b_username[i]]))\n",
    "\n",
    "UNPairs = pd.DataFrame()\n",
    "UNPairs['Pairs'] = pairs\n",
    "UNPairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmotDF['Pairs'] = UNPairs['Pairs']\n",
    "\n",
    "count = Counter(EmotDF['Pairs'])\n",
    "print('UN Count Length:',len(count)) # generates count of all the usernames. len should be 69148\n",
    "\n",
    "# Drop the usernames from DF with fewer than 10 instances in the conversation\n",
    "for k in list(count):\n",
    "    if count[k] < 10: # Delete tweet-reply username pairs with fewer than 10 messages\n",
    "        del count[k]\n",
    "print('Dropped Count Length: ',len(count)) # Should be 7392\n",
    "\n",
    "#Turn Counter dictionary into list:\n",
    "countList = []\n",
    "for item in list(count):\n",
    "    countList.append(item)\n",
    "countList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop rows from dataframe that aren't consistent with usernames in Countlist - with sufficient number ot analyze\n",
    "newSentDF = EmotDF[EmotDF['Pairs'].isin(countList)]\n",
    "newSentDF = newSentDF.reset_index()\n",
    "newSentDF[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174857"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call on below function with sentiment markers: \n",
    "#markers = ['anger','anticipation','disgust','fear','joy','sadness','surprise','trust']\n",
    "shared = scp.getSharedMarkers(newSentDF['ASent'],newSentDF['BSent'])\n",
    "len(shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScores = nrc.fullForm(countList,newSentDF,markers,shared) # input: (UNList,Dataframe,markers,sharedlist)\n",
    "len(allScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write df to CSV\n",
    "allScoresDF = pd.DataFrame.from_dict(allScores,orient='index')\n",
    "allScoresDF.to_csv('SCP_Acc_Scores_SentHash.csv',sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScoresDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanscol = allScoresDF.mean(axis = 0)\n",
    "meanscolDF = meanscol.to_frame()#.reset_index()\n",
    "meanscolDF.columns=['Score']\n",
    "meanscolDF=meanscolDF.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanscolDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average difference between minuend and subtrahend estimations\n",
    "scoreDict = {}\n",
    "for i in range(len(meanscolDF)):\n",
    "    if i%2 == 1:\n",
    "        scoreDict[meanscolDF['index'][i-1]]= (meanscolDF['Score'][i] - meanscolDF['Score'][i-1]) \n",
    "scoreDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average difference between minuend and subtrahend estimations for\n",
    "ScoreListBAvg = {}\n",
    "ScoreListBGivA = {}\n",
    "for i in range(len(meanscolDF)):\n",
    "    if i%2 == 0:\n",
    "        ScoreListBAvg[meanscolDF['index'][i]] = meanscolDF['Score'][i]\n",
    "    elif i%2 == 1:\n",
    "        ScoreListBGivA[meanscolDF['index'][i-1]] = meanscolDF['Score'][i]\n",
    "len(ScoreListBGivA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreDictDF = pd.DataFrame.from_dict(scoreDict, orient='index')\n",
    "scoreDictDF.columns = ['Accommodation']\n",
    "scoreDictDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoreListBGivA = pd.DataFrame.from_dict(ScoreListBGivA,orient='index')\n",
    "ScoreListBAvg = pd.DataFrame.from_dict(ScoreListBAvg,orient='index')\n",
    "ScoreListBAvg.columns = ['B']\n",
    "ScoreListBGivA.columns = ['B|A']\n",
    "scoreDictDF['BAvg'] = ScoreListBAvg['B']\n",
    "scoreDictDF['BGivenA'] = ScoreListBGivA['B|A']\n",
    "scoreDictDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreToPlotBar = scoreDictDF.copy()\n",
    "scoreToPlotBar = scoreToPlotBar.drop(['Accommodation'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Visualizations and save tables\n",
    "with open ('SCP_SentHash_Accomodation.tex','w') as tf:\n",
    "    tf.write(scoreDictDF.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataframe to horizontal bar chart\n",
    "plot1 = scoreToPlotBar.plot(kind = 'bar')#,figsize = (15,7))#, stacked = True)#,figsize = (20,10))\n",
    "                    \n",
    "#plot1.tick_params(labelbottom=False, bottom=False,which='both')\n",
    "plt.ylabel('SCP Score')\n",
    "plt.xlabel('Sentiment Marker')\n",
    "plt.title('SCP - Accommodation')\n",
    "plt.savefig('Accommodation_AllVals_NRCHashSent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize just accommodation score\n",
    "# Visualize dataframe to horizontal bar chart\n",
    "plot1 = scoreDictDF['Accommodation'].sort_values().plot(kind = 'barh',color='steelblue')#,figsize = (15,10))\n",
    "                    \n",
    "#plot1.tick_params(labelbottom=False, bottom=False,which='both')\n",
    "plt.xlabel('SCP Score')\n",
    "plt.ylabel('Emotion Marker')\n",
    "plt.title('SCP - Accommodation')\n",
    "plt.savefig('Accommodation_Diff_Score_NRCHashSent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Tailed P Test for sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTestDict = {}\n",
    "for marker in markers:\n",
    "    TTestDict[marker] = (stats.ttest_rel(allScoresDF[marker],allScoresDF[marker+'2']))\n",
    "TTestDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScoresDF.fillna(0.0000001, inplace=True)\n",
    "allScoresDF.fillna(0.0000001, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTestDF = pd.DataFrame.from_dict(TTestDict,orient='index')\n",
    "TTestDF =TTestDF.drop('statistic',axis=1)\n",
    "TTestDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('Accom_TTest_Emot.tex','w') as tf:\n",
    "    tf.write(TTestDF.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
